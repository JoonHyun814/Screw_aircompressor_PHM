{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "def data_preprocess(data,sequence_num,step):\n",
    "    X_train = []\n",
    "    for i in range(0,len(data)-sequence_num,step):\n",
    "        X_train.append(data[i:i+sequence_num])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    return X_train\n",
    "\n",
    "def data_normalization(data):\n",
    "    pres_cm_in_max = 1000\n",
    "    pres_cm_in_min = 0\n",
    "    pres_mr_max = 900\n",
    "    pres_mr_min = 600\n",
    "    temp_cm_oil_max = 120\n",
    "    temp_cm_oil_min = 20\n",
    "    curr_max = 30\n",
    "    curr_min = 0\n",
    "    data.iloc[:,0]  = (data.iloc[:,0] -pres_cm_in_min)/(pres_cm_in_max-pres_cm_in_min)\n",
    "    data.iloc[:,1]  = (data.iloc[:,1] -pres_mr_min)/(pres_mr_max-pres_mr_min)\n",
    "    data.iloc[:,2]  = (data.iloc[:,2] -temp_cm_oil_min)/(temp_cm_oil_max-temp_cm_oil_min)\n",
    "    data.iloc[:,7]  = (data.iloc[:,7] -curr_min)/(curr_max-curr_min)\n",
    "    data.iloc[:,8]  = (data.iloc[:,8] -curr_min)/(curr_max-curr_min)\n",
    "    data.iloc[:,9]  = (data.iloc[:,9] -curr_min)/(curr_max-curr_min)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UsingFeatures = ['pres_cm_in','pres_mr','temp_cm_oil','valv_1','vibr_x_u', 'vibr_y_u', 'vibr_z_u',\n",
    "                 'curr_u','curr_v', 'curr_w']\n",
    "datas = []\n",
    "for i in range(1,11):\n",
    "    data = pd.read_csv('../data/205train/205train_cmsd_tc1_2020_12_%02d.csv' %i)\n",
    "    data = data[UsingFeatures]\n",
    "    datas.append(data)\n",
    "    \n",
    "datas_2 = []\n",
    "for data in datas:\n",
    "    data = data_normalization(data)\n",
    "    data = data_preprocess(data,100,10)\n",
    "    datas_2.append(data)\n",
    "data = np.concatenate(datas_2)\n",
    "\n",
    "# 훈련 데이터 셋 생성 X 값은 이전 상태량과 다음 전류값, Y 값은 다음 상태량\n",
    "X_train = []\n",
    "for i in range(len(data)-10):\n",
    "    X_train.append(np.concatenate((data[i][:,[0,1,2,3,4,5,6]],data[i+10][:,[7,8,9]]),axis=1))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "Y_train = []\n",
    "for i in range(10,len(data)):\n",
    "    Y_train.append(data[i][:,[0,1,2,3,4,5,6]])\n",
    "    \n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# 결측값 제거\n",
    "nan_list = list(np.where(np.isnan(X_train)==True)[0])\n",
    "X_train = np.delete(X_train, nan_list,0)\n",
    "Y_train = np.delete(Y_train, nan_list,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 10)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 8)            608       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 8)            544       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 7)            448       \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LSTM_model(X):    \n",
    "    x = tf.keras.layers.Input(shape=[X.shape[1],X.shape[2]])\n",
    "    H = LSTM(8,activation = 'sigmoid', return_sequences = True)(x)\n",
    "    H = LSTM(8,activation = 'sigmoid', return_sequences = True)(H)\n",
    "    Y = LSTM(7,activation = 'sigmoid', return_sequences = True)(H)\n",
    "    model = Model(x, Y)\n",
    "    return model\n",
    "\n",
    "model = LSTM_model(X_train)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam,loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15221/15221 [==============================] - 648s 42ms/step - loss: 0.0619 - val_loss: 0.0187\n",
      "Epoch 2/100\n",
      "15221/15221 [==============================] - 638s 42ms/step - loss: 0.0220 - val_loss: 0.0169\n",
      "Epoch 3/100\n",
      "15221/15221 [==============================] - 624s 41ms/step - loss: 0.0207 - val_loss: 0.0153\n",
      "Epoch 4/100\n",
      "15221/15221 [==============================] - 621s 41ms/step - loss: 0.0188 - val_loss: 0.0118\n",
      "Epoch 5/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0163 - val_loss: 0.0106\n",
      "Epoch 6/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 7/100\n",
      "15221/15221 [==============================] - 627s 41ms/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 8/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 9/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0150 - val_loss: 0.0097\n",
      "Epoch 10/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "15221/15221 [==============================] - 625s 41ms/step - loss: 0.0144 - val_loss: 0.0092\n",
      "Epoch 12/100\n",
      "15221/15221 [==============================] - 626s 41ms/step - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 13/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 14/100\n",
      "15221/15221 [==============================] - 630s 41ms/step - loss: 0.0139 - val_loss: 0.0091\n",
      "Epoch 15/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0139 - val_loss: 0.0088\n",
      "Epoch 16/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 17/100\n",
      "15221/15221 [==============================] - 630s 41ms/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 18/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 19/100\n",
      "15221/15221 [==============================] - 632s 42ms/step - loss: 0.0136 - val_loss: 0.0087\n",
      "Epoch 20/100\n",
      "15221/15221 [==============================] - 628s 41ms/step - loss: 0.0136 - val_loss: 0.0085\n",
      "Epoch 21/100\n",
      "15221/15221 [==============================] - 621s 41ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 22/100\n",
      "15221/15221 [==============================] - 623s 41ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 23/100\n",
      "15221/15221 [==============================] - 624s 41ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 24/100\n",
      "15221/15221 [==============================] - 625s 41ms/step - loss: 0.0134 - val_loss: 0.0086\n",
      "Epoch 25/100\n",
      "15221/15221 [==============================] - 628s 41ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 26/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0134 - val_loss: 0.0082\n",
      "Epoch 27/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0134 - val_loss: 0.0086\n",
      "Epoch 28/100\n",
      "15221/15221 [==============================] - 630s 41ms/step - loss: 0.0133 - val_loss: 0.0086\n",
      "Epoch 29/100\n",
      "15221/15221 [==============================] - 632s 42ms/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 30/100\n",
      "15221/15221 [==============================] - 632s 42ms/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 31/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 32/100\n",
      "15221/15221 [==============================] - 633s 42ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 33/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 34/100\n",
      "15221/15221 [==============================] - 630s 41ms/step - loss: 0.0132 - val_loss: 0.0084\n",
      "Epoch 35/100\n",
      "15221/15221 [==============================] - 636s 42ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 36/100\n",
      "15221/15221 [==============================] - 637s 42ms/step - loss: 0.0132 - val_loss: 0.0080\n",
      "Epoch 37/100\n",
      "15221/15221 [==============================] - 636s 42ms/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 38/100\n",
      "15221/15221 [==============================] - 635s 42ms/step - loss: 0.0131 - val_loss: 0.0083\n",
      "Epoch 39/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 40/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0131 - val_loss: 0.0079\n",
      "Epoch 41/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 42/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 43/100\n",
      "15221/15221 [==============================] - 631s 41ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 44/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0129 - val_loss: 0.0081\n",
      "Epoch 45/100\n",
      "15221/15221 [==============================] - 629s 41ms/step - loss: 0.0129 - val_loss: 0.0080\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train,Y_train,epochs = 100,batch_size = 20, callbacks=[early_stopping],validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_predict_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/205train/205train_cmsd_tc1_2021_03_14.csv')\n",
    "data = data[UsingFeatures]\n",
    "\n",
    "data = data_normalization(data)\n",
    "data = data_preprocess(data,100,10)\n",
    "\n",
    "# 훈련 데이터 셋 생성 X 값은 이전 상태량과 다음 전류값, Y 값은 다음 상태량\n",
    "X_test = np.array([np.concatenate((data[i][:,[0,1,2,3,4,5,6]],data[i+10][:,[7,8,9]]),axis=1) for i in range(len(data) -10)])\n",
    "\n",
    "Y_test = np.array([data[i][:,[0,1,2,3,4,5,6]] for i in range(10,len(data))])\n",
    "\n",
    "# 결측값 제거\n",
    "nan_list = list(np.where(np.isnan(X_train)==True)[0])\n",
    "X_test = np.delete(X_test, nan_list,0)\n",
    "Y_test = np.delete(Y_test, nan_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mae(pred,test):\n",
    "    loss_mae = []\n",
    "    for i in range(len(list(pred))):\n",
    "        loss = abs(test[i]-pred[i])\n",
    "        loss_mae.append(loss.sum(axis=1).sum(axis=0)/(pred.shape[1]*pred.shape[2]))\n",
    "    return np.array(loss_mae)\n",
    "\n",
    "MAE = loss_mae(pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean       Var\n",
       "0  0.023242  0.000177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[[np.mean(MAE),np.var(MAE)]]\n",
    "column_labels=[\"Mean\", \"Var\"]\n",
    "df=pd.DataFrame(data,columns=column_labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
